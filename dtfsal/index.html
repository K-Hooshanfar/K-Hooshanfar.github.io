<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="DTFSal: Audio-Visual Dynamic Token Fusion for Video Saliency Prediction">
  <meta name="keywords" content="DTFSal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DTFSal</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <!-- <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div> -->
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">DTFSal: Audio-Visual Dynamic Token Fusion for Video Saliency Prediction</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=-qqc3AUAAAAJ&hl=en">Kiana Hooshanfar</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=6lxGXlkAAAAJ&hl=en">Alireza Hosseini</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=m7xdmMgAAAAJ&hl=en">Ahmad Kalhor</a><sup>*</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=en&user=FTcata0AAAAJ">Babak Nadjar Araabi</a><sup>*</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>University of Tehran</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming soon)</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <img id="teaser" src="./static/main_fig.png" alt="Teaser Image" style="max-width: 100%; height: auto;">
      <h2 class="subtitle has-text-centered" style="font-size: 1rem;"> Overview of our DTFSal model, which integrates a multi-scale encoder, a hierarchical multi-decoder, LTEB, DLTFB, and AMFB for efficient and accurate audio-visual saliency prediction.
      </h2>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
           <p>
            Audio-visual saliency prediction aims to mimic human visual attention by identifying salient regions in videos through
            the integration of both visual and auditory information. Although visual-only approaches have significantly advanced, 
            effectively incorporating auditory cues remains challenging due to complex spatioâ€“temporal interactions and high computational demands. 
            To address these challenges, we propose <strong>D</strong>ynamic <strong>T</strong>oken <strong>F</strong>usion <strong>Sal</strong>iency (DFTSal), 
            a novel audio-visual saliency prediction framework designed to balance accuracy with computational efficiency. 
            Our approach features a multi-scale visual encoder equipped with two novel modules: the Learnable Token Enhancement Block (LTEB), 
            which adaptively weights tokens to emphasize crucial saliency cues, and the Dynamic Learnable Token Fusion Block (DLTFB), 
            which employs a shifting operation to reorganize and merge features, effectively capturing long-range dependencies and detailed spatial information. 
            In parallel, an audio branch processes raw audio signals to extract meaningful auditory features. Both visual and audio features are integrated using 
            our Adaptive Multimodal Fusion Block (AMFB), which employs local, global, and adaptive fusion streams for precise cross-modal fusion. 
            The resulting fused features are processed by a hierarchical multi-decoder structure, producing accurate saliency maps. 
            Extensive evaluations on six audio-visual benchmarks demonstrate that DFTSal achieves SOTA performance while maintaining computational efficiency.
          </p>         
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!--/ Paper video. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
  <div class="columns is-centered">
    <div class="column is-full-width">
      <h2 class="title is-3">DTFSal: Experimental Results Across Audio-Visual Datasets</h2>

      <div class="content has-text-justified">
        <img src="static/results1.png" alt="Experimental Results" width="100%">
        <p class="has-text-centered">
          <em> Comparison with previous methods on six audio-visual saliency datasets. For our model, we indicate the percentage (%) change in performance relative to the second-best result, or to the best result if ours is not the top performer. The best results are highlighted in <span style="color:red;">red</span>, the second-best in <span style="color:blue;">blue</span>, and the third-best in <span style="color:darkgreen;">dark green</span>.
          </em>
        </p>
      </div>
    </div>
  </div>

  <div class="columns is-centered">
    <div class="column is-9">
      <h2 class="title is-4">Performance on Visual Only Datasets</h2>
      <div class="content has-text-justified">
        <img src="static/results2.png" alt="visual only Performance" width="130%">
        <p class="has-text-centered">
          <em>  Comparison with Previous Methods on DHF1K and UCF Sports Datasets. For our model, we indicate the percentage (%) change in performance relative to the second-best result, or to the best result if ours is not the top performer. The best results are highlighted in <span style="color:red;">red</span>, the second-best in <span style="color:blue;">blue</span>, and the third-best in <span style="color:darkgreen;">green</span>.
          </em>
        </p>
      </div>
    </div>
  </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    
    <!-- Title for Experimental Results -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">DTFSal: Qualitative Results of Saliency maps</h2>
      </div>
    </div>

    
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h3 class="title is-4">Qualitative Results of Audio-Visual Saliency maps</h3>
        <div class="content has-text-centered">
          <img src="static/av_fig.png" alt="av_fig" width="100%">
          <p><em>Figure: Comparative visualizations of our DTFSal model compared with previous SOTA audio-visual saliency prediction methods.</em></p>
        </div>
      </div>
    </div>

    <br>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <div class="content has-text-centered">
          <img src="static/av_fig2.png" alt="av_fig2" width="100%">
          <p><em>Figure: Additional comparative visualizations of our DTFSal model compared with previous SOTA audio-visual saliency prediction methods.</em></p>
        </div>
      </div>
    </div>

    <br>

    
    <!-- Image Denoising -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h3 class="title is-4">Qualitative Results of Visual Only Saliency maps</h3>
        <div class="content has-text-centered">
          <img src="static/visual_fig.png" alt="visual only Results" width="100%">
          <p><em>Figure: Comparative visualizations of our DTFSal model compared with previous SOTA visual-only saliency prediction methods.</em></p>
        </div>
      </div>
    </div>
    
    
    <br>  
    

      </div>
    </section>
    
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{,
        author    = {Kiana Hoshanfar and Alireza Hosseini and Ahmad Kalhor and Babak Nadjar Araabi},
        title     = {DTFSal: Audio-Visual Dynamic Token Fusion for Video Saliency Prediction},
        eprint   = { },
        year      = {2025},
        url={ },
}</code></pre>
  </div>
</section>

<!-- <footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We thank the authors of <a href="https://nerfies.github.io/">Nerfies</a> for kindly open-sourcing the template of this website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer> -->


<footer class="footer">
  <div class="container" style="text-align: center;">  <h2 style="font-size: 2em; font-weight: bold;">Contact</h2> 
    <p>For Questions, Clarifications and Colaborations, please get in touch with:</p>

    <br><br>
    <div class="email text-center">
      <i class="bi bi-envelope"></i>
      <p style="font-size: larger; font-weight: bold;"><a href="mailto:k.hooshanfar02@gmail.com">k.hooshanfar02@gmail.com</a></p>
    </div>
    </div>
</footer>


</body>
</html>
