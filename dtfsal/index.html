<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="DTFSal: Audio-Visual Dynamic Token Fusion for Video Saliency Prediction">
  <meta name="keywords" content="DTFSal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DTFSal</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <!-- <script src="./static/js/index.js"></script> -->
</head>
<body>

  <script>
    let paperSource = '';
    fetch('./paper.txt')           // ← point at the actual filename
      .then(r => {
        if (!r.ok) throw new Error(r.status);
        return r.text();
      })
      .then(text => { paperSource = text; })
      .catch(err => console.error('Couldn’t load paper.txt:', err));
  </script>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <!-- <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div> -->
</nav>

  <!-- Inline Styles for Conversation Bubbles -->
  <style>
    /* Container for the chat messages */
    #chat-log {
      display: flex;
      flex-direction: column;
      gap: 10px;
      padding: 10px;
      background: #fafafa;
      height: 300px;
      overflow-y: auto;
      border: 1px solid #ddd;
      border-radius: 5px;
    }
    /* Common styling for all messages */
    .message {
      padding: 10px 15px;
      border-radius: 15px;
      max-width: 70%;
      word-wrap: break-word;
    }
    /* User messages appear on the right */
    .user-message {
      background-color: #007bff;
      color: #fff;
      align-self: flex-end;
      text-align: right;
    }
    /* Bot messages appear on the left */
    .bot-message {
      background-color: #f1f0f0;
      color: #333;
      align-self: flex-start;
      text-align: left;
    }
  </style>

  <!-- Gemini API details -->
  <script>
    const KEY = "AIzaSyDcHo_x2I0oGF2pK1YMlLVSpBNb94BtGoI";
    const GEMINI_API_ENDPOINT = 
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=" 
      + KEY;
  </script>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">DTFSal: Audio-Visual Dynamic Token Fusion for Video Saliency Prediction</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=-qqc3AUAAAAJ&hl=en">Kiana Hooshanfar</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=6lxGXlkAAAAJ&hl=en">Alireza Hosseini</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=m7xdmMgAAAAJ&hl=en">Ahmad Kalhor</a><sup>*</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=en&user=FTcata0AAAAJ">Babak Nadjar Araabi</a><sup>*</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>University of Tehran</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming soon)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <img id="teaser" src="./static/main_fig.png" alt="Teaser Image" style="max-width: 100%; height: auto;">
      <h2 class="subtitle has-text-centered" style="font-size: 1rem;"> Overview of our DTFSal model, which integrates a multi-scale encoder, a hierarchical multi-decoder, LTEB, DLTFB, and AMFB for efficient and accurate audio-visual saliency prediction.
      </h2>
    </div>
  </div>
</section>

<!-- ===== Paper Chatbot ===== -->
<section id="chat-widget" class="section">
  <div class="container is-max-desktop">
    <div class="card">
      <div class="card-content">

        <!-- Header + Reset -->
        <div class="level mb-4">
          <div class="level-left">
            <h2 class="title is-4">Chat about this Paper</h2>
          </div>
          <div class="level-right">
            <button id="reset-chat" class="button is-light">Reset</button>
          </div>
        </div>

        <!-- Suggested Questions -->
        <div class="buttons mb-3">
          <button class="button is-small suggestion-btn" data-question="What is the main contribution?">Contribution</button>
          <button class="button is-small suggestion-btn" data-question="Who are the authors?">Authors</button>
          <button class="button is-small suggestion-btn" data-question="Explain DFTSal.">DFTSal</button>
          <button class="button is-small suggestion-btn" data-question="How does the LTEB block work?">LTEB</button>
          <button class="button is-small suggestion-btn" data-question="Show the BibTeX entry.">BibTeX</button>
        </div>

        <!-- Chat Log -->
        <div id="chat-log"></div>

        <!-- Chat Input -->
        <form id="chat-form" class="field has-addons">
          <div class="control is-expanded">
            <input id="chat-input" class="input" type="text"
                   placeholder="Ask a question about the paper…" required>
          </div>
          <div class="control">
            <button type="submit" class="button is-primary">Send</button>
          </div>
        </form>

      </div>
    </div>
  </div>
</section>
<!-- ===== End Chatbot ===== -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
           <p>
            Audio-visual saliency prediction aims to mimic human visual attention by identifying salient regions in videos through
            the integration of both visual and auditory information. Although visual-only approaches have significantly advanced, 
            effectively incorporating auditory cues remains challenging due to complex spatio–temporal interactions and high computational demands. 
            To address these challenges, we propose <strong>D</strong>ynamic <strong>T</strong>oken <strong>F</strong>usion <strong>Sal</strong>iency (DFTSal), 
            a novel audio-visual saliency prediction framework designed to balance accuracy with computational efficiency. 
            Our approach features a multi-scale visual encoder equipped with two novel modules: the Learnable Token Enhancement Block (LTEB), 
            which adaptively weights tokens to emphasize crucial saliency cues, and the Dynamic Learnable Token Fusion Block (DLTFB), 
            which employs a shifting operation to reorganize and merge features, effectively capturing long-range dependencies and detailed spatial information. 
            In parallel, an audio branch processes raw audio signals to extract meaningful auditory features. Both visual and audio features are integrated using 
            our Adaptive Multimodal Fusion Block (AMFB), which employs local, global, and adaptive fusion streams for precise cross-modal fusion. 
            The resulting fused features are processed by a hierarchical multi-decoder structure, producing accurate saliency maps. 
            Extensive evaluations on six audio-visual benchmarks demonstrate that DFTSal achieves SOTA performance while maintaining computational efficiency.
          </p>         
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!--/ Paper video. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
  <div class="columns is-centered">
    <div class="column is-full-width">
      <h2 class="title is-3">DTFSal: Experimental Results Across Audio-Visual Datasets</h2>

      <div class="content has-text-justified">
        <img src="static/results1.png" alt="Experimental Results" width="100%">
        <p class="has-text-centered">
          <em> Comparison with previous methods on six audio-visual saliency datasets. For our model, we indicate the percentage (%) change in performance relative to the second-best result, or to the best result if ours is not the top performer. The best results are highlighted in <span style="color:red;">red</span>, the second-best in <span style="color:blue;">blue</span>, and the third-best in <span style="color:darkgreen;">dark green</span>.
          </em>
        </p>
      </div>
    </div>
  </div>

  <div class="columns is-centered">
    <div class="column is-9">
      <h2 class="title is-4">Performance on Visual Only Datasets</h2>
      <div class="content has-text-justified">
        <img src="static/results2.png" alt="visual only Performance" width="130%">
        <p class="has-text-centered">
          <em>  Comparison with Previous Methods on DHF1K and UCF Sports Datasets. For our model, we indicate the percentage (%) change in performance relative to the second-best result, or to the best result if ours is not the top performer. The best results are highlighted in <span style="color:red;">red</span>, the second-best in <span style="color:blue;">blue</span>, and the third-best in <span style="color:darkgreen;">green</span>.
          </em>
        </p>
      </div>
    </div>
  </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    
    <!-- Title for Experimental Results -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">DTFSal: Qualitative Results of Saliency maps</h2>
      </div>
    </div>

    
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h3 class="title is-4">Qualitative Results of Audio-Visual Saliency maps</h3>
        <div class="content has-text-centered">
          <img src="static/av_fig.png" alt="av_fig" width="100%">
          <p><em>Figure: Comparative visualizations of our DTFSal model compared with previous SOTA audio-visual saliency prediction methods.</em></p>
        </div>
      </div>
    </div>

    <br>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <div class="content has-text-centered">
          <img src="static/av_fig2.png" alt="av_fig2" width="100%">
          <p><em>Figure: Additional comparative visualizations of our DTFSal model compared with previous SOTA audio-visual saliency prediction methods.</em></p>
        </div>
      </div>
    </div>

    <br>

    
    <!-- Image Denoising -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h3 class="title is-4">Qualitative Results of Visual Only Saliency maps</h3>
        <div class="content has-text-centered">
          <img src="static/visual_fig.png" alt="visual only Results" width="100%">
          <p><em>Figure: Comparative visualizations of our DTFSal model compared with previous SOTA visual-only saliency prediction methods.</em></p>
        </div>
      </div>
    </div>
    
    
    <br>  
    

      </div>
    </section>
    
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{,
        author    = {Kiana Hoshanfar and Alireza Hosseini and Ahmad Kalhor and Babak Nadjar Araabi},
        title     = {DTFSal: Audio-Visual Dynamic Token Fusion for Video Saliency Prediction},
        eprint   = { },
        year      = {2025},
        url={ },
}</code></pre>
  </div>
</section>

<!-- <footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We thank the authors of <a href="https://nerfies.github.io/">Nerfies</a> for kindly open-sourcing the template of this website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer> -->


<footer class="footer">
  <div class="container" style="text-align: center;">  <h2 style="font-size: 2em; font-weight: bold;">Contact</h2> 
    <p>For Questions, Clarifications and Colaborations, please get in touch with:</p>

    <br><br>
    <div class="email text-center">
      <i class="bi bi-envelope"></i>
      <p style="font-size: larger; font-weight: bold;"><a href="mailto:k.hooshanfar02@gmail.com">k.hooshanfar02@gmail.com</a></p>
    </div>
    </div>
</footer>

<script>
  // Append a chat message to the DOM
  function appendMessage(text, sender) {
    const log = document.getElementById('chat-log');
    const msg = document.createElement('div');
    msg.classList.add('message', sender === 'user' ? 'user-message' : 'bot-message');
    msg.textContent = text;
    log.appendChild(msg);
    log.scrollTop = log.scrollHeight;
  }

      // Post‑processing: bold and equations
    // Enhanced post‑processing: bold, lists, paragraphs, equations
    function formatReply(text) {
      // 1) bold → <strong>
      let out = text.replace(/\*\*(.+?)\*\*/g, '<strong>$1</strong>');

      // 2) break out inline “: * ” bullets into their own lines
      out = out.replace(/:\s*\* /g, ':\n* ');

      // 3) one‑line equations → <pre><code>
      out = out.replace(
  /^(.+=.+)$/gm,
  (_, eq) => {
    // 1) convert subscript: _{foo} or _x → <sub>foo</sub> or <sub>x</sub>
    let htmlEq = eq.replace(
      /_(\{([^}]+)\}|(\w))/g,
      (_, _all, braced, single) => `<sub>${braced || single}</sub>`
    );

    // 2) convert superscript: ^{foo} or ^x → <sup>foo</sup> or <sup>x</sup>
    htmlEq = htmlEq.replace(
      /\^(\{([^}]+)\}|(\w))/g,
      (_, _all, braced, single) => `<sup>${braced || single}</sup>`
    );

    // 3) convert double‑prime: P'' → P<sup>''</sup>
    htmlEq = htmlEq.replace(
      /([A-Za-z0-9\}])''/g,
      '$1<sup>\'\'</sup>'
    );

    // 4) wrap it all in a code block
    return `<pre><code>${htmlEq}</code></pre>`;
  }
);

      // 4) split lines, build lists and paragraphs
      const lines = out.split('\n');
      let html = '';
      let inList = false;

      for (let line of lines) {
        if (/^\*\s+/.test(line)) {
          // start or continue a list
          if (!inList) {
            html += '<ul>';
            inList = true;
          }
          html += `<li>${line.replace(/^\*\s+/, '')}</li>`;
        } else {
          // close any open list
          if (inList) {
            html += '</ul>';
            inList = false;
          }

          if (/^\s*<pre>/.test(line)) {
            // already a code block
            html += line;
          } else if (line.trim() !== '') {
            // normal paragraph
            html += `<p>${line.trim()}</p>`;
          }
          // else: skip blank lines
        }
      }

      // if we ended inside a list, close it
      if (inList) {
        html += '</ul>';
      }

      return html;
    }

  // Reset chat
  document.getElementById('reset-chat').addEventListener('click', () => {
    document.getElementById('chat-log').innerHTML = '';
  });

  // Handle suggestion buttons
  document.querySelectorAll('.suggestion-btn').forEach(btn => {
    btn.addEventListener('click', () => {
      const q = btn.dataset.question;
      document.getElementById('chat-input').value = q;
      document.getElementById('chat-form').dispatchEvent(new Event('submit'));
    });
  });

  // Handle form submit
  document.getElementById('chat-form').addEventListener('submit', async e => {
    e.preventDefault();
    const input = document.getElementById('chat-input');
    const question = input.value.trim();
    if (!question) return;
    appendMessage(question, 'user');
    input.value = '';

    // Show a typing indicator
    appendMessage('...', 'bot');

    // Build prompt
    const prompt = `
You are an AI assistant tasked with answering questions based *exclusively* on the provided LaTeX source document.

**Your Goal:** Provide a short clear, structured, and accurate answers synthesized *only* from the information present in the LaTeX source.

**LaTeX Source:**
\`\`\`latex
${paperSource}
\`\`\`

**Instructions for Generating Your Answer:**

1.  **Relevance:** Directly address the user's question. Find all relevant information within the source to construct your answer.
2.  **Structure:**
    * Organize your answer logically. Use paragraphs for explanations.
    * Use bullet points for lists or distinct points if it enhances clarity.
    * Ensure the answer flows well and is easy to understand.
3.  **Synthesis:** Do not just copy-paste sections. Synthesize the information from the relevant parts of the source into a coherent response. Rephrase in your own words, while staying true to the source content.
4.  **LaTeX and Math Formatting:**
    * **No Delimiters:** Absolutely *no* LaTeX delimiters (like \\( \\), \\[ \\], $ $, $$ $$) should appear in your output.
    * **Plain Text Math:** Render *all* mathematical notation (variables, formulas, symbols, Greek letters, etc.) as plain text.
        * Example: Write E(t) instead of \\(\\mathbf{E}(t)\\).
        * Example: Write alpha_i instead of \\(\\alpha_i\\).
        * Example: Write x^2 + y^2 = z^2 instead of \\(x^2 + y^2 = z^2\\).
    * **Equations:**
        * If the answer requires showing specific equations from the source:
        * Present each relevant equation on a new line.
        * Use clear, readable plain text format for the equation itself.
        * You may add a brief label or explanation before or after the equation *if* it helps clarify its relevance to the answer, based *only* on the source text surrounding the equation. Example: "The equation for calculating force is:" followed by the plain text equation on the next line.
5.  **Out-of-Scope Questions:** If the user's question cannot be answered using *only* the provided LaTeX source, reply *exactly* with:
    "I'm sorry, I can only answer questions about this paper."

User: ${question}
Assistant:
`;

try {
        const res = await fetch(GEMINI_API_ENDPOINT, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ contents: [{ parts: [{ text: prompt }] }] })
        });
        if (!res.ok) throw new Error(`API ${res.status}`);
        const data = await res.json();
        let reply = data.candidates?.[0]?.content?.parts?.[0]?.text.trim() || 'No response.';
        // Replace the typing indicator with formatted HTML
        const log = document.getElementById('chat-log');
        log.lastChild.innerHTML = formatReply(reply);
      } catch (err) {
        const log = document.getElementById('chat-log');
        log.lastChild.textContent = 'Error: ' + err.message;
        console.error(err);
      }
    });
  </script>

</body>
</html>